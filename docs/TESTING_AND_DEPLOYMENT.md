# æµ‹è¯•å’Œéƒ¨ç½²æŒ‡å—

æœ¬æ–‡æ¡£æä¾›äº†è‚¡ç¥¨æ¨èç³»ç»Ÿçš„å®Œæ•´æµ‹è¯•å’Œéƒ¨ç½²æ–¹æ¡ˆï¼ŒåŒ…æ‹¬APIæµ‹è¯•ã€Dockeréƒ¨ç½²ã€æ—¥å¿—è®°å½•å’Œæµç¨‹éªŒè¯ã€‚

## ä¸€ã€APIæ¥å£æµ‹è¯•

### 1.1 Postmanæµ‹è¯•é›†åˆ

#### ç¯å¢ƒå˜é‡è®¾ç½®
```json
{
  "base_url": "http://localhost:8000",
  "api_version": "v1"
}
```

#### æ ¸å¿ƒæ¥å£æµ‹è¯•ç”¨ä¾‹

**1. è·å–ä¹°å…¥æ¨è**
```
GET {{base_url}}/api/{{api_version}}/recommendations/buy
Query Params:
- limit: 10
- date: 2024-01-15
- min_confidence: 0.7

é¢„æœŸå“åº”ç»“æ„:
{
  "code": 200,
  "message": "success",
  "data": [
    {
      "id": "uuid",
      "stockCode": "000001",
      "stockName": "å¹³å®‰é“¶è¡Œ",
      "currentPrice": 12.50,
      "targetPrice": 14.00,
      "stopLoss": 11.50,
      "confidence": 0.85,
      "reason": "æŠ€æœ¯æŒ‡æ ‡æ˜¾ç¤ºçªç ´å…³é”®é˜»åŠ›ä½",
      "strategyName": "MAå‡çº¿ç­–ç•¥",
      "createdAt": "2024-01-15T09:30:00Z"
    }
  ]
}
```

**2. è·å–å–å‡ºæ¨è**
```
GET {{base_url}}/api/{{api_version}}/recommendations/sell
Query Params:
- limit: 10
- date: 2024-01-15

é¢„æœŸå“åº”ç»“æ„: åŒä¹°å…¥æ¨è
```

**3. ç”Ÿæˆæ¨è**
```
POST {{base_url}}/api/{{api_version}}/recommendations/generate
Content-Type: application/json

{
  "stockCodes": ["000001", "600036"],
  "strategies": ["ma_strategy", "rsi_strategy"],
  "parameters": {
    "minConfidence": 0.7
  }
}

é¢„æœŸå“åº”:
{
  "code": 200,
  "message": "success",
  "data": {
    "taskId": "uuid",
    "status": "processing",
    "message": "æ¨èç”Ÿæˆä»»åŠ¡å·²æäº¤"
  }
}
```

**4. è‚¡ç¥¨æœç´¢**
```
GET {{base_url}}/api/{{api_version}}/stocks/search
Query Params:
- keyword: å¹³å®‰
- limit: 10

é¢„æœŸå“åº”:
{
  "code": 200,
  "message": "success",
  "data": [
    {
      "code": "000001",
      "name": "å¹³å®‰é“¶è¡Œ",
      "market": "A",
      "industry": "é“¶è¡Œ",
      "currentPrice": 12.50,
      "changePercent": 2.5
    }
  ]
}
```

**5. Kçº¿æ•°æ®**
```
GET {{base_url}}/api/{{api_version}}/stocks/000001/kline
Query Params:
- period: daily
- start_date: 2024-01-01
- end_date: 2024-01-15

é¢„æœŸå“åº”:
{
  "code": 200,
  "message": "success",
  "data": {
    "stockCode": "000001",
    "stockName": "å¹³å®‰é“¶è¡Œ",
    "klineData": [
      {
        "date": "2024-01-15",
        "open": 12.20,
        "high": 12.80,
        "low": 12.10,
        "close": 12.50,
        "volume": 1000000,
        "amount": 12500000.0
      }
    ]
  }
}
```

### 1.2 è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬

åˆ›å»º `tests/postman_tests.py`ï¼š
```python
import requests
import json
from datetime import datetime

class APITester:
    def __init__(self, base_url="http://localhost:8000"):
        self.base_url = base_url
        self.api_version = "v1"
        
    def test_buy_recommendations(self):
        """æµ‹è¯•ä¹°å…¥æ¨èæ¥å£"""
        url = f"{self.base_url}/api/{self.api_version}/recommendations/buy"
        params = {"limit": 10, "min_confidence": 0.7}
        
        response = requests.get(url, params=params)
        assert response.status_code == 200
        
        data = response.json()
        assert "code" in data
        assert "data" in data
        assert data["code"] == 200
        
        print("âœ… ä¹°å…¥æ¨èæ¥å£æµ‹è¯•é€šè¿‡")
        return data
    
    def test_stock_search(self):
        """æµ‹è¯•è‚¡ç¥¨æœç´¢æ¥å£"""
        url = f"{self.base_url}/api/{self.api_version}/stocks/search"
        params = {"keyword": "å¹³å®‰", "limit": 10}
        
        response = requests.get(url, params=params)
        assert response.status_code == 200
        
        data = response.json()
        assert data["code"] == 200
        assert len(data["data"]) > 0
        
        print("âœ… è‚¡ç¥¨æœç´¢æ¥å£æµ‹è¯•é€šè¿‡")
        return data
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("å¼€å§‹APIæ¥å£æµ‹è¯•...")
        
        try:
            self.test_buy_recommendations()
            self.test_stock_search()
            print("\nğŸ‰ æ‰€æœ‰APIæµ‹è¯•é€šè¿‡ï¼")
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    tester = APITester()
    tester.run_all_tests()
```

## äºŒã€Docker Composeéƒ¨ç½²

### 2.1 ä¼˜åŒ–çš„docker-compose.yml

```yaml
version: '3.8'

services:
  # åç«¯APIæœåŠ¡
  backend:
    build: 
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:password@postgres:5432/stock_db
      - REDIS_URL=redis://redis:6379/0
      - PYTHONPATH=/app
      - LOG_LEVEL=INFO
      - CORS_ORIGINS=http://localhost:3000,http://localhost:8087
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./backend:/app
      - ./data:/app/data
      - ./strategies:/app/strategies
      - ./config:/app/config
      - ./logs:/app/logs
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
    networks:
      - stock-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # å‰ç«¯æœåŠ¡
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - VITE_API_BASE_URL=http://localhost:8000
      - NODE_ENV=development
    volumes:
      - ./frontend:/app
      - /app/node_modules
    command: npm run dev -- --host 0.0.0.0 --port 3000
    networks:
      - stock-network
    depends_on:
      - backend

  # PostgreSQLæ•°æ®åº“
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=stock_db
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - POSTGRES_INITDB_ARGS=--encoding=UTF-8 --lc-collate=C --lc-ctype=C
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - stock-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redisç¼“å­˜
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - stock-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  # Nginxåå‘ä»£ç†ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
    depends_on:
      - backend
      - frontend
    networks:
      - stock-network
    profiles:
      - production

volumes:
  postgres_data:
  redis_data:

networks:
  stock-network:
    driver: bridge
```

### 2.2 Nginxé…ç½®ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰

åˆ›å»º `nginx/nginx.conf`ï¼š
```nginx
events {
    worker_connections 1024;
}

http {
    upstream backend {
        server backend:8000;
    }
    
    upstream frontend {
        server frontend:3000;
    }
    
    # å‰ç«¯æœåŠ¡
    server {
        listen 80;
        server_name localhost;
        
        # å‰ç«¯é™æ€èµ„æº
        location / {
            proxy_pass http://frontend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
        
        # APIæ¥å£
        location /api/ {
            proxy_pass http://backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # CORSè®¾ç½®
            add_header Access-Control-Allow-Origin *;
            add_header Access-Control-Allow-Methods "GET, POST, PUT, DELETE, OPTIONS";
            add_header Access-Control-Allow-Headers "Content-Type, Authorization";
            
            if ($request_method = 'OPTIONS') {
                return 204;
            }
        }
        
        # APIæ–‡æ¡£
        location /docs {
            proxy_pass http://backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
    }
}
```

### 2.3 éƒ¨ç½²è„šæœ¬

åˆ›å»º `scripts/deploy.sh`ï¼š
```bash
#!/bin/bash

set -e

echo "ğŸš€ å¼€å§‹éƒ¨ç½²è‚¡ç¥¨æ¨èç³»ç»Ÿ..."

# æ£€æŸ¥Dockerå’ŒDocker Compose
if ! command -v docker &> /dev/null; then
    echo "âŒ Dockeræœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…Docker"
    exit 1
fi

if ! command -v docker-compose &> /dev/null; then
    echo "âŒ Docker Composeæœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…Docker Compose"
    exit 1
fi

# åˆ›å»ºå¿…è¦çš„ç›®å½•
mkdir -p logs data/csv data/cache

# åœæ­¢ç°æœ‰æœåŠ¡
echo "ğŸ“¦ åœæ­¢ç°æœ‰æœåŠ¡..."
docker-compose down

# æ„å»ºé•œåƒ
echo "ğŸ”¨ æ„å»ºDockeré•œåƒ..."
docker-compose build --no-cache

# å¯åŠ¨æœåŠ¡
echo "ğŸš€ å¯åŠ¨æœåŠ¡..."
docker-compose up -d

# ç­‰å¾…æœåŠ¡å¯åŠ¨
echo "â³ ç­‰å¾…æœåŠ¡å¯åŠ¨..."
sleep 30

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
echo "ğŸ” æ£€æŸ¥æœåŠ¡çŠ¶æ€..."
docker-compose ps

# æµ‹è¯•APIè¿æ¥
echo "ğŸ§ª æµ‹è¯•APIè¿æ¥..."
if curl -f http://localhost:8000/health > /dev/null 2>&1; then
    echo "âœ… åç«¯APIæœåŠ¡æ­£å¸¸"
else
    echo "âŒ åç«¯APIæœåŠ¡å¼‚å¸¸"
fi

if curl -f http://localhost:3000 > /dev/null 2>&1; then
    echo "âœ… å‰ç«¯æœåŠ¡æ­£å¸¸"
else
    echo "âŒ å‰ç«¯æœåŠ¡å¼‚å¸¸"
fi

echo "ğŸ‰ éƒ¨ç½²å®Œæˆï¼"
echo "ğŸ“Š å‰ç«¯åœ°å€: http://localhost:3000"
echo "ğŸ“¡ APIæ–‡æ¡£: http://localhost:8000/docs"
echo "ğŸ“ˆ APIåœ°å€: http://localhost:8000/api/v1"
```

## ä¸‰ã€æ—¥å¿—è®°å½•ç³»ç»Ÿ

### 3.1 å¢å¼ºçš„æ—¥å¿—é…ç½®

åˆ›å»º `backend/app/core/logging.py`ï¼š
```python
import os
import sys
from loguru import logger
from datetime import datetime
from config.settings import settings

def setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    
    # ç§»é™¤é»˜è®¤å¤„ç†å™¨
    logger.remove()
    
    # æ§åˆ¶å°è¾“å‡º
    logger.add(
        sys.stdout,
        format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
        level=settings.LOG_LEVEL,
        colorize=True
    )
    
    # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
    os.makedirs(settings.LOG_DIR, exist_ok=True)
    
    # åº”ç”¨æ—¥å¿—æ–‡ä»¶
    logger.add(
        os.path.join(settings.LOG_DIR, "app.log"),
        format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}",
        level=settings.LOG_LEVEL,
        rotation="1 day",
        retention="30 days",
        compression="zip"
    )
    
    # æ¨èç”Ÿæˆä¸“ç”¨æ—¥å¿—
    logger.add(
        os.path.join(settings.LOG_DIR, "recommendations.log"),
        format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {message}",
        level="INFO",
        rotation="1 day",
        retention="90 days",
        filter=lambda record: "recommendation" in record["name"].lower()
    )
    
    # é”™è¯¯æ—¥å¿—æ–‡ä»¶
    logger.add(
        os.path.join(settings.LOG_DIR, "errors.log"),
        format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}\n{exception}",
        level="ERROR",
        rotation="1 week",
        retention="12 weeks"
    )
    
    return logger

class RecommendationLogger:
    """æ¨èç”Ÿæˆä¸“ç”¨æ—¥å¿—è®°å½•å™¨"""
    
    def __init__(self):
        self.logger = logger.bind(name="recommendation")
    
    def log_generation_start(self, task_id: str, stock_codes: list, strategies: list):
        """è®°å½•æ¨èç”Ÿæˆå¼€å§‹"""
        self.logger.info(
            f"æ¨èç”Ÿæˆå¼€å§‹ - ä»»åŠ¡ID: {task_id} | "
            f"è‚¡ç¥¨æ•°é‡: {len(stock_codes)} | "
            f"ç­–ç•¥: {', '.join(strategies)} | "
            f"å¼€å§‹æ—¶é—´: {datetime.now()}"
        )
    
    def log_generation_complete(self, task_id: str, recommendations_count: int, duration: float):
        """è®°å½•æ¨èç”Ÿæˆå®Œæˆ"""
        self.logger.info(
            f"æ¨èç”Ÿæˆå®Œæˆ - ä»»åŠ¡ID: {task_id} | "
            f"ç”Ÿæˆæ•°é‡: {recommendations_count} | "
            f"è€—æ—¶: {duration:.2f}ç§’ | "
            f"å®Œæˆæ—¶é—´: {datetime.now()}"
        )
    
    def log_generation_error(self, task_id: str, error: str):
        """è®°å½•æ¨èç”Ÿæˆé”™è¯¯"""
        self.logger.error(
            f"æ¨èç”Ÿæˆå¤±è´¥ - ä»»åŠ¡ID: {task_id} | "
            f"é”™è¯¯ä¿¡æ¯: {error} | "
            f"å¤±è´¥æ—¶é—´: {datetime.now()}"
        )
    
    def log_strategy_execution(self, strategy_name: str, stock_code: str, result: dict):
        """è®°å½•ç­–ç•¥æ‰§è¡Œç»“æœ"""
        self.logger.info(
            f"ç­–ç•¥æ‰§è¡Œ - ç­–ç•¥: {strategy_name} | "
            f"è‚¡ç¥¨: {stock_code} | "
            f"ä¿¡å·: {result.get('signal', 'none')} | "
            f"ç½®ä¿¡åº¦: {result.get('confidence', 0):.3f}"
        )
```

### 3.2 æ¨èæœåŠ¡æ—¥å¿—å¢å¼º

æ›´æ–° `backend/app/services/recommendation_service.py`ï¼š
```python
from app.core.logging import RecommendationLogger
import time
import uuid

class RecommendationService:
    def __init__(self, db: Session):
        self.db = db
        self.rec_logger = RecommendationLogger()
    
    async def generate_recommendations(self, stock_codes: list, strategies: list, parameters: dict):
        """ç”Ÿæˆæ¨èï¼ˆå¢å¼ºæ—¥å¿—è®°å½•ï¼‰"""
        task_id = str(uuid.uuid4())
        start_time = time.time()
        
        # è®°å½•å¼€å§‹
        self.rec_logger.log_generation_start(task_id, stock_codes, strategies)
        
        try:
            recommendations = []
            
            for stock_code in stock_codes:
                for strategy_name in strategies:
                    try:
                        # æ‰§è¡Œç­–ç•¥
                        result = await self._execute_strategy(strategy_name, stock_code, parameters)
                        
                        # è®°å½•ç­–ç•¥æ‰§è¡Œç»“æœ
                        self.rec_logger.log_strategy_execution(strategy_name, stock_code, result)
                        
                        if result.get('signal') in ['buy', 'sell']:
                            recommendations.append(result)
                            
                    except Exception as e:
                        self.rec_logger.log_generation_error(task_id, f"ç­–ç•¥æ‰§è¡Œå¤±è´¥: {strategy_name} - {stock_code} - {str(e)}")
            
            # è®°å½•å®Œæˆ
            duration = time.time() - start_time
            self.rec_logger.log_generation_complete(task_id, len(recommendations), duration)
            
            return {
                "task_id": task_id,
                "recommendations": recommendations,
                "duration": duration
            }
            
        except Exception as e:
            self.rec_logger.log_generation_error(task_id, str(e))
            raise
```

## å››ã€å®Œæ•´æµç¨‹éªŒè¯

### 4.1 ç«¯åˆ°ç«¯æµ‹è¯•è„šæœ¬

åˆ›å»º `scripts/e2e_test.py`ï¼š
```python
#!/usr/bin/env python3

import requests
import time
import json
from datetime import datetime, timedelta

class E2ETestSuite:
    """ç«¯åˆ°ç«¯æµ‹è¯•å¥—ä»¶"""
    
    def __init__(self, backend_url="http://localhost:8000", frontend_url="http://localhost:3000"):
        self.backend_url = backend_url
        self.frontend_url = frontend_url
        self.test_stocks = ["000001", "600036", "000002"]  # æµ‹è¯•è‚¡ç¥¨ä»£ç 
        
    def test_backend_health(self):
        """æµ‹è¯•åç«¯å¥åº·çŠ¶æ€"""
        print("ğŸ” æµ‹è¯•åç«¯å¥åº·çŠ¶æ€...")
        response = requests.get(f"{self.backend_url}/health")
        assert response.status_code == 200
        print("âœ… åç«¯æœåŠ¡æ­£å¸¸")
        
    def test_frontend_access(self):
        """æµ‹è¯•å‰ç«¯è®¿é—®"""
        print("ğŸ” æµ‹è¯•å‰ç«¯è®¿é—®...")
        response = requests.get(self.frontend_url)
        assert response.status_code == 200
        print("âœ… å‰ç«¯æœåŠ¡æ­£å¸¸")
        
    def test_stock_data_preparation(self):
        """æµ‹è¯•è‚¡ç¥¨æ•°æ®å‡†å¤‡"""
        print("ğŸ” æµ‹è¯•è‚¡ç¥¨æ•°æ®å‡†å¤‡...")
        
        # æ£€æŸ¥è‚¡ç¥¨æ˜¯å¦å­˜åœ¨
        for stock_code in self.test_stocks:
            response = requests.get(f"{self.backend_url}/api/v1/stocks/{stock_code}")
            if response.status_code == 404:
                # å¦‚æœè‚¡ç¥¨ä¸å­˜åœ¨ï¼Œæ·»åŠ æµ‹è¯•æ•°æ®
                self._add_test_stock_data(stock_code)
                
        print("âœ… è‚¡ç¥¨æ•°æ®å‡†å¤‡å®Œæˆ")
        
    def test_recommendation_generation(self):
        """æµ‹è¯•æ¨èç”Ÿæˆæµç¨‹"""
        print("ğŸ” æµ‹è¯•æ¨èç”Ÿæˆæµç¨‹...")
        
        # ç”Ÿæˆæ¨è
        payload = {
            "stockCodes": self.test_stocks,
            "strategies": ["ma_strategy", "rsi_strategy"],
            "parameters": {
                "minConfidence": 0.6
            }
        }
        
        response = requests.post(
            f"{self.backend_url}/api/v1/recommendations/generate",
            json=payload
        )
        
        assert response.status_code == 200
        result = response.json()
        task_id = result["data"]["taskId"]
        
        print(f"âœ… æ¨èç”Ÿæˆä»»åŠ¡æäº¤æˆåŠŸï¼Œä»»åŠ¡ID: {task_id}")
        
        # ç­‰å¾…ç”Ÿæˆå®Œæˆ
        time.sleep(5)
        
        return task_id
        
    def test_recommendation_retrieval(self):
        """æµ‹è¯•æ¨èè·å–"""
        print("ğŸ” æµ‹è¯•æ¨èè·å–...")
        
        # è·å–ä¹°å…¥æ¨è
        response = requests.get(f"{self.backend_url}/api/v1/recommendations/buy?limit=10")
        assert response.status_code == 200
        
        buy_recommendations = response.json()["data"]
        print(f"âœ… è·å–åˆ° {len(buy_recommendations)} æ¡ä¹°å…¥æ¨è")
        
        # è·å–å–å‡ºæ¨è
        response = requests.get(f"{self.backend_url}/api/v1/recommendations/sell?limit=10")
        assert response.status_code == 200
        
        sell_recommendations = response.json()["data"]
        print(f"âœ… è·å–åˆ° {len(sell_recommendations)} æ¡å–å‡ºæ¨è")
        
        return buy_recommendations, sell_recommendations
        
    def test_frontend_display(self, recommendations):
        """æµ‹è¯•å‰ç«¯æ˜¾ç¤ºï¼ˆæ¨¡æ‹Ÿï¼‰"""
        print("ğŸ” æµ‹è¯•å‰ç«¯æ˜¾ç¤º...")
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ Seleniumæµ‹è¯•æˆ–APIè°ƒç”¨æµ‹è¯•
        # æš‚æ—¶é€šè¿‡æ£€æŸ¥æ¨èæ•°æ®ç»“æ„æ¥éªŒè¯
        
        for rec in recommendations[:3]:  # æ£€æŸ¥å‰3æ¡æ¨è
            required_fields = [
                'stockCode', 'stockName', 'currentPrice', 
                'targetPrice', 'confidence', 'reason'
            ]
            
            for field in required_fields:
                assert field in rec, f"æ¨èæ•°æ®ç¼ºå°‘å­—æ®µ: {field}"
                
        print("âœ… æ¨èæ•°æ®ç»“æ„éªŒè¯é€šè¿‡")
        
    def _add_test_stock_data(self, stock_code):
        """æ·»åŠ æµ‹è¯•è‚¡ç¥¨æ•°æ®"""
        stock_data = {
            "code": stock_code,
            "name": f"æµ‹è¯•è‚¡ç¥¨{stock_code}",
            "market": "A",
            "industry": "æµ‹è¯•è¡Œä¸š"
        }
        
        response = requests.post(
            f"{self.backend_url}/api/v1/stocks",
            json=stock_data
        )
        
        if response.status_code in [200, 201]:
            print(f"âœ… æ·»åŠ æµ‹è¯•è‚¡ç¥¨: {stock_code}")
        
    def run_full_test(self):
        """è¿è¡Œå®Œæ•´æµ‹è¯•æµç¨‹"""
        print("ğŸš€ å¼€å§‹ç«¯åˆ°ç«¯æµ‹è¯•...\n")
        
        try:
            # 1. æµ‹è¯•æœåŠ¡å¥åº·çŠ¶æ€
            self.test_backend_health()
            self.test_frontend_access()
            
            # 2. å‡†å¤‡æµ‹è¯•æ•°æ®
            self.test_stock_data_preparation()
            
            # 3. æµ‹è¯•æ¨èç”Ÿæˆ
            task_id = self.test_recommendation_generation()
            
            # 4. æµ‹è¯•æ¨èè·å–
            buy_recs, sell_recs = self.test_recommendation_retrieval()
            
            # 5. æµ‹è¯•å‰ç«¯æ˜¾ç¤º
            if buy_recs:
                self.test_frontend_display(buy_recs)
            
            print("\nğŸ‰ ç«¯åˆ°ç«¯æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
            
            # è¾“å‡ºæµ‹è¯•æŠ¥å‘Š
            self._generate_test_report(task_id, buy_recs, sell_recs)
            
        except Exception as e:
            print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
            raise
            
    def _generate_test_report(self, task_id, buy_recs, sell_recs):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        report = {
            "æµ‹è¯•æ—¶é—´": datetime.now().isoformat(),
            "ä»»åŠ¡ID": task_id,
            "ä¹°å…¥æ¨èæ•°é‡": len(buy_recs),
            "å–å‡ºæ¨èæ•°é‡": len(sell_recs),
            "æµ‹è¯•è‚¡ç¥¨": self.test_stocks,
            "æµ‹è¯•ç»“æœ": "é€šè¿‡"
        }
        
        with open("test_report.json", "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
            
        print(f"\nğŸ“Š æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ° test_report.json")
        print(f"ğŸ“ˆ ä¹°å…¥æ¨è: {len(buy_recs)} æ¡")
        print(f"ğŸ“‰ å–å‡ºæ¨è: {len(sell_recs)} æ¡")

if __name__ == "__main__":
    tester = E2ETestSuite()
    tester.run_full_test()
```

### 4.2 æ•°æ®å‡†å¤‡è„šæœ¬

åˆ›å»º `scripts/prepare_test_data.py`ï¼š
```python
#!/usr/bin/env python3

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os

def generate_test_stock_data():
    """ç”Ÿæˆæµ‹è¯•è‚¡ç¥¨æ•°æ®"""
    
    # æµ‹è¯•è‚¡ç¥¨åˆ—è¡¨
    test_stocks = [
        {"code": "000001", "name": "å¹³å®‰é“¶è¡Œ", "industry": "é“¶è¡Œ"},
        {"code": "600036", "name": "æ‹›å•†é“¶è¡Œ", "industry": "é“¶è¡Œ"},
        {"code": "000002", "name": "ä¸‡ç§‘A", "industry": "æˆ¿åœ°äº§"},
        {"code": "600519", "name": "è´µå·èŒ…å°", "industry": "ç™½é…’"},
        {"code": "000858", "name": "äº”ç²®æ¶²", "industry": "ç™½é…’"}
    ]
    
    # ç¡®ä¿CSVç›®å½•å­˜åœ¨
    csv_dir = "data/csv"
    os.makedirs(csv_dir, exist_ok=True)
    
    # ç”Ÿæˆè‚¡ç¥¨åŸºç¡€ä¿¡æ¯
    stocks_df = pd.DataFrame(test_stocks)
    stocks_df.to_csv(f"{csv_dir}/stocks.csv", index=False, encoding="utf-8")
    
    # ç”Ÿæˆä»·æ ¼æ•°æ®
    end_date = datetime.now().date()
    start_date = end_date - timedelta(days=365)  # ä¸€å¹´çš„æ•°æ®
    
    all_price_data = []
    
    for stock in test_stocks:
        stock_code = stock["code"]
        
        # ç”Ÿæˆæ¨¡æ‹Ÿä»·æ ¼æ•°æ®
        dates = pd.date_range(start=start_date, end=end_date, freq='D')
        
        # æ¨¡æ‹Ÿä»·æ ¼èµ°åŠ¿
        base_price = np.random.uniform(10, 100)  # åŸºç¡€ä»·æ ¼
        price_trend = np.cumsum(np.random.normal(0, 0.02, len(dates)))  # ä»·æ ¼è¶‹åŠ¿
        
        for i, date in enumerate(dates):
            # è·³è¿‡å‘¨æœ«
            if date.weekday() >= 5:
                continue
                
            daily_change = np.random.normal(0, 0.03)  # æ—¥å†…æ³¢åŠ¨
            
            open_price = base_price * (1 + price_trend[i] + daily_change)
            close_price = open_price * (1 + np.random.normal(0, 0.02))
            high_price = max(open_price, close_price) * (1 + abs(np.random.normal(0, 0.01)))
            low_price = min(open_price, close_price) * (1 - abs(np.random.normal(0, 0.01)))
            
            volume = int(np.random.uniform(1000000, 10000000))  # æˆäº¤é‡
            amount = volume * close_price  # æˆäº¤é¢
            
            all_price_data.append({
                "stock_code": stock_code,
                "date": date.strftime("%Y-%m-%d"),
                "open": round(open_price, 2),
                "high": round(high_price, 2),
                "low": round(low_price, 2),
                "close": round(close_price, 2),
                "volume": volume,
                "amount": round(amount, 2),
                "turnover_rate": round(np.random.uniform(0.5, 5.0), 2)
            })
    
    # ä¿å­˜ä»·æ ¼æ•°æ®
    price_df = pd.DataFrame(all_price_data)
    price_df.to_csv(f"{csv_dir}/stock_prices.csv", index=False, encoding="utf-8")
    
    print(f"âœ… æµ‹è¯•æ•°æ®ç”Ÿæˆå®Œæˆ:")
    print(f"   - è‚¡ç¥¨æ•°é‡: {len(test_stocks)}")
    print(f"   - ä»·æ ¼æ•°æ®: {len(all_price_data)} æ¡")
    print(f"   - æ•°æ®ç›®å½•: {csv_dir}")
    
    return test_stocks, all_price_data

if __name__ == "__main__":
    generate_test_stock_data()
```

## äº”ã€ä½¿ç”¨æŒ‡å—

### 5.1 å¿«é€Ÿéƒ¨ç½²

```bash
# 1. å…‹éš†é¡¹ç›®
git clone <repository-url>
cd stock

# 2. å‡†å¤‡æµ‹è¯•æ•°æ®
python3 scripts/prepare_test_data.py

# 3. éƒ¨ç½²æœåŠ¡
bash scripts/deploy.sh

# 4. è¿è¡Œç«¯åˆ°ç«¯æµ‹è¯•
python3 scripts/e2e_test.py

# 5. è¿è¡ŒAPIæµ‹è¯•
python3 tests/postman_tests.py
```

### 5.2 æ—¥å¿—æŸ¥çœ‹

```bash
# æŸ¥çœ‹åº”ç”¨æ—¥å¿—
tail -f logs/app.log

# æŸ¥çœ‹æ¨èç”Ÿæˆæ—¥å¿—
tail -f logs/recommendations.log

# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
tail -f logs/errors.log

# æŸ¥çœ‹Dockerå®¹å™¨æ—¥å¿—
docker-compose logs -f backend
docker-compose logs -f frontend
```

### 5.3 ç›‘æ§å’Œç»´æŠ¤

```bash
# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps

# é‡å¯æœåŠ¡
docker-compose restart

# æŸ¥çœ‹èµ„æºä½¿ç”¨
docker stats

# æ¸…ç†æ—¥å¿—ï¼ˆä¿ç•™æœ€è¿‘30å¤©ï¼‰
find logs/ -name "*.log" -mtime +30 -delete
```

## å…­ã€æ•…éšœæ’é™¤

### 6.1 å¸¸è§é—®é¢˜

**é—®é¢˜1: ç«¯å£å†²çª**
```bash
# æ£€æŸ¥ç«¯å£å ç”¨
netstat -tulpn | grep :8000
netstat -tulpn | grep :3000

# ä¿®æ”¹docker-compose.ymlä¸­çš„ç«¯å£æ˜ å°„
```

**é—®é¢˜2: æ•°æ®åº“è¿æ¥å¤±è´¥**
```bash
# æ£€æŸ¥PostgreSQLçŠ¶æ€
docker-compose logs postgres

# é‡ç½®æ•°æ®åº“
docker-compose down
docker volume rm stock_postgres_data
docker-compose up -d
```

**é—®é¢˜3: å‰ç«¯æ— æ³•è®¿é—®åç«¯API**
```bash
# æ£€æŸ¥CORSé…ç½®
# ç¡®è®¤backend/app/main.pyä¸­çš„CORSè®¾ç½®
# æ£€æŸ¥nginxé…ç½®ï¼ˆå¦‚æœä½¿ç”¨ï¼‰
```

### 6.2 æ€§èƒ½ä¼˜åŒ–

1. **æ•°æ®åº“ä¼˜åŒ–**
   - æ·»åŠ é€‚å½“çš„ç´¢å¼•
   - å®šæœŸæ¸…ç†å†å²æ•°æ®
   - ä½¿ç”¨è¿æ¥æ± 

2. **ç¼“å­˜ä¼˜åŒ–**
   - å¯ç”¨Redisç¼“å­˜
   - è®¾ç½®åˆé€‚çš„ç¼“å­˜è¿‡æœŸæ—¶é—´
   - ç¼“å­˜çƒ­ç‚¹æ•°æ®

3. **APIä¼˜åŒ–**
   - å®ç°åˆ†é¡µæŸ¥è¯¢
   - æ·»åŠ è¯·æ±‚é™æµ
   - ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢

é€šè¿‡ä»¥ä¸Šå®Œæ•´çš„æµ‹è¯•å’Œéƒ¨ç½²æ–¹æ¡ˆï¼Œå¯ä»¥ç¡®ä¿è‚¡ç¥¨æ¨èç³»ç»Ÿçš„ç¨³å®šè¿è¡Œå’ŒæŒç»­ç›‘æ§ã€‚